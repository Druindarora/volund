# ğŸ§  Whisper Server â€“ Environnement de dÃ©veloppement Parlia

> ğŸ•’ DerniÃ¨re mise Ã  jour : 9 juillet 2025 Ã  16h30  
> â±ï¸ Temps de dÃ©veloppement estimÃ© : 1h30

Ce microservice local permet de faire tourner Whisper en arriÃ¨re-plan pendant le dÃ©veloppement de Parlia, pour Ã©viter de recharger le modÃ¨le Ã  chaque fois.

---

## ğŸš€ Fonctionnement

- Le serveur dÃ©marre avec **FastAPI**
- Il charge **une seule fois** le modÃ¨le Whisper (**par dÃ©faut : `tiny`**)
- Il expose une route POST `/transcribe` qui accepte un fichier `.wav` et retourne le texte transcrit
- Il tourne en local : `http://127.0.0.1:5005`

---

## ğŸ“ Structure

dev_env/
â”œâ”€â”€ whisper_server.py # Serveur FastAPI (Whisper intÃ©grÃ©)
â”œâ”€â”€ start_whisper_server.bat # Script de lancement Windows
â””â”€â”€ README.md # Ce fichier

---

## ğŸ“¦ DÃ©pendances requises

Installe-les dans ton environnement virtuel avec :

```bash
pip install fastapi uvicorn whisper python-multipart

ğŸ§ª Pour lancer le serveur
Active ton environnement virtuel Python (venv)

Lance simplement le script Windows :
start_whisper_server.bat
Celui-ci appelle le bon interprÃ©teur Python pour dÃ©marrer le serveur.

ğŸ“¤ API
POST /transcribe
Champ requis (form-data) : audio_file (format .wav)

RÃ©ponse :

json
Copier
Modifier
{
  "text": "Texte dictÃ© par l'utilisateur."
}
En cas dâ€™erreur, la rÃ©ponse contiendra un champ "error" et un code HTTP 500.

ğŸ§° Logs console
Des logs lisibles sont affichÃ©s dans la console :

Chargement du modÃ¨le ([ğŸ”Š])

Fichier reÃ§u ([ğŸ“¥])

Chemin temporaire ([ğŸ§ª])

RÃ©sultat de la transcription ([ğŸ“])

Nettoyage ([ğŸ§¹])

Erreurs Ã©ventuelles ([âŒ])

ğŸ”’ SÃ©curitÃ©
Ce microservice n'est pas sÃ©curisÃ© : il ne doit Ãªtre utilisÃ© qu'en local dans un environnement de dÃ©veloppement.